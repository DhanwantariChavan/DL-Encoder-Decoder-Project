ğŸ“° Headline Generator using Encoder-Decoder and Transformer Models
A Comparative Study of LSTM Models Without Attention, With Attention, and Transformers for News Headline Generation
This project explores automated news headline generation using three deep learning architectures:

Basic LSTM Encoder-Decoder (without attention)

LSTM Encoder-Decoder with Attention

Transformer Model (Self-Attention)

We evaluate and compare performance using BLEU and ROUGE metrics, aiming to understand how attention mechanisms and self-attention impact summarization quality.

ğŸ” Project Overview
ğŸ”§ Architectures Implemented:
LSTM Encoder-Decoder (No Attention):
Simple sequence-to-sequence model with greedy decoding.

LSTM with Attention:
Uses a bidirectional encoder and additive attention mechanism. Helps the decoder focus on relevant parts of the input sequence.

Transformer:
Implements self-attention, positional encoding, and parallelized computation as per â€œAttention Is All You Needâ€.

ğŸ“‚ Dataset & Preprocessing
Input: CSV file with text (news articles) and headlines.

Preprocessing Steps:

Lowercasing, punctuation removal, tokenization (NLTK)

Vocabulary built from tokens with frequency â‰¥ 2

Special tokens: <pad>, <sos>, <eos>, <unk>

Padding: Articles â†’ 400 tokens, Headlines â†’ 20 tokens

Dataset Split: 80% Train, 10% Validation, 10% Test

ğŸ“Š Evaluation Metrics
BLEU (1â€“4)

ROUGE (ROUGE-1, ROUGE-2, ROUGE-L)

These metrics are calculated across all three models for fair comparison.

ğŸ“ˆ Key Results
Model	BLEU-4	ROUGE-L	Inference Time
LSTM (No Attention)	âœ… Basic	âœ… Baseline	ğŸ•’ Slow
LSTM + Attention	ğŸ”¼ Better context	ğŸ”¼ Higher fluency	âš¡ Faster
Transformer	â­ Highest	â­ Best coherence	âš¡âš¡ Fastest

Actual metric values are displayed in the notebook.

ğŸ“Œ Key Findings
Attention significantly improves coherence and relevance.

Transformers outperform LSTM-based models in both speed and quality.

Attention maps offer interpretable predictions.

Cleaned data and curated vocabulary boost accuracy.

ğŸ›  Libraries & Tools Used
Python, PyTorch, NLTK, Matplotlib

BLEU/ROUGE metrics
